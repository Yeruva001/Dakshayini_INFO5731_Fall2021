{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DakshayiniRayini/Dakshayini_INFO5731_Fall2021/blob/main/Dakshayini_INFO5731_Fall2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRgyUHKHqjXS"
      },
      "source": [
        "## The second In-class-exercise (09/22/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5FGJgORqjXU"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-C0AHKzqjXV"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wzqmIIG6qjXW",
        "outputId": "a3aa8c65-96a4-42a2-e4f1-1de2e0fd9b1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\n\\n. The research question I have to analyse is the places to be visited by the tourists.\\n. For this, I have to collect the data of the search history o the tourists that are visible to users from website by using filters. \\n. It is regarding sentinent analysis.\\n. We can collect the data and then plot to analyse the search history as analysis.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        ". The research question I have to analyse is the places to be visited by the tourists based on the previous search history.\n",
        ". For this, I have to collect the data of the search history of the tourists that are visible to users from website by using filters of places that have searched. \n",
        ". It is regarding search analysis.\n",
        ". We can collect the data and then plot to analyse the search history as analysis.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpkJaMKfqjXX"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPYoapENqjXX",
        "outputId": "0e3a3f2e-8c2f-4082-e5f4-44047e9201b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.amazon.com/s?k=iphone+10\n",
            "https://www.amazon.com/s?k=UnderArmour+shoes+men\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def getAmazon(sea_qu):\n",
        "    url1=\"https://www.amazon.com/s?k=\"+sea_qu\n",
        "    print(url1)\n",
        "    pg=requests.get(url1,headers=header)\n",
        "    if pg.status_code==200:\n",
        "        return pg\n",
        "    else:\n",
        "        return \"Error\"\n",
        "\n",
        "s_query=\"iphone+10\"\n",
        "base_url=\"https://www.amazon.com/s?k=\"\n",
        "\n",
        "url_1=base_url+s_query\n",
        "\n",
        "header={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36','referer':'https://www.amazon.com/s?k=nike+shoes+men&crid=28WRS5SFLWWZ6&sprefix=nike%2Caps%2C357&ref=nb_sb_ss_organic-diversity_2_4'}\n",
        "\n",
        "s_response=requests.get(url_1,headers=header)\n",
        "\n",
        "cookies={} \n",
        "cookies_1 = s_response.cookies\n",
        "prod_name=[]\n",
        "resp=getAmazon('iphone+10')\n",
        "so=BeautifulSoup(resp.content)\n",
        "for i in so.findAll(\"span\",{'class':'a-size-base-plus a-color-base a-text-normal'}): \n",
        "    prod_name.append(i.text) \n",
        "def Searchasing(asin1):\n",
        "    url1=\"https://www.amazon.com/dp/\"+asin1\n",
        "    print(url1)\n",
        "    pg=requests.get(url1,cookies=cookies_1,headers=header)\n",
        "    if pg.status_code==200:\n",
        "        return pg\n",
        "    else:\n",
        "        return \"Error\"\n",
        "def Searchrev(rev_li):\n",
        "    url_2=\"https://www.amazon.com\"+rev_li\n",
        "    print(url_2)\n",
        "    pg=requests.get(url_2,cookies=cookies_1,headers=header)\n",
        "    if pg.status_code==200:\n",
        "        return pg\n",
        "    else:\n",
        "        return \"Error\"\n",
        "data_asign=[]\n",
        "resp=getAmazon('UnderArmour+shoes+men')\n",
        "so=BeautifulSoup(resp.content)\n",
        "\n",
        "for i in so.findAll(\"div\",class_=\"sg-col-4-of-12 s-result-item s-asin sg-col-4-of-16 AdHolder sg-col sg-col-4-of-20\"):\n",
        "\n",
        "    data_asign.append(i['data-asign'])\n",
        "li=[]\n",
        "for i in range(len(data_asign)):\n",
        "    resp=Searchasing(data_asign[i])\n",
        "    so=BeautifulSoup(resp.content)\n",
        "    for i in so.findAll(\"a\",{'data-hook':\"see-all-reviews-link-foot\"}):\n",
        "        li.append(i['href'])\n",
        "rev=[]\n",
        "rev_title = []\n",
        "rev_date = []\n",
        "rev_star = []\n",
        "name1 = []\n",
        "for j in range(len(li)):\n",
        "    for k in range(50):\n",
        "        resp=Searchrev(li[j]+'&pageNumber='+str(k))\n",
        "        so=BeautifulSoup(resp.content)\n",
        "        for i in so.findAll(\"span\",{'data-hook':\"review-body\"}):\n",
        "            rev.append(i.text)\n",
        "        for i in so.findAll(\"span\",{'data-hook':\"review-title\"}):\n",
        "            rev_title.append(i.text)\n",
        "        for i in so.findAll(\"span\",{'data-hook':\"review-date\"}):\n",
        "            rev_date.append(i.text)\n",
        "        for i in so.findAll(\"span\",{'data-hook':\"review-star-rating\"}):\n",
        "            rev_star.append(i.text)\n",
        "        for i in so.findAll('span',class_='a-profile-name'):\n",
        "            name1.append(i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIsU4qkBqjXY"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX3rjN66qjXY",
        "outputId": "6a7d0578-a788-4bae-b45e-47d59ee0f812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "                                               Title  \\\n",
            "0                              Information Retrieval   \n",
            "1                       Modern Information Retrieval   \n",
            "2                      Private Information Retrieval   \n",
            "3           An Introduction to Information Retrieval   \n",
            "4  Naive (Bayes) at Forty: The Independence Assum...   \n",
            "\n",
            "                                   Authors  Year  \\\n",
            "0                        C.J.vanRijsbergen  1979   \n",
            "1  RicardoBaeza-Yates,BerthierRibeiro-Neto  1999   \n",
            "2                          BennyChor,etal.     0   \n",
            "3               ChristopherD.Manning,etal.  2007   \n",
            "4                             DavidD.Lewis  1998   \n",
            "\n",
            "                                            Abstract  \n",
            "0                                        \"...   ...\"  \n",
            "1  \"... Information retrieval (IR) has changed co...  \n",
            "2  \"...   We describe schemes that enable a user ...  \n",
            "3                                        \"...   ...\"  \n",
            "4  \"... The naive Bayes classifier, currently exp...  \n",
            "(500, 4)\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "    \n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import HTTPError\n",
        "import json\n",
        "import re \n",
        "import pandas as pd\n",
        "final_count = 0\n",
        "c = 0\n",
        "\n",
        "result = {\"Title\":[], \"Authors\":[], \"Year\":[], \"Abstract\":[]}\n",
        "main_url = \"https://citeseerx.ist.psu.edu/search?q=information+retrieval&t=doc&sort=rlv&start={}\"\n",
        "for page_num in range(0, 5000, 10):\n",
        "    \n",
        "    l1 = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    url1 = urlopen(l1)\n",
        "\n",
        "    d1 = url1.read()\n",
        "    d1_soup = BeautifulSoup(d1)\n",
        "    \n",
        "    \n",
        "    for i in d1_soup.find_all(\"a\", attrs={'class':'remove doc_details'}):\n",
        "        \n",
        "        result[\"Title\"].append(i.text.strip())\n",
        "        \n",
        "    for i in d1_soup.find_all(\"div\", attrs={'class':'pubinfo'}):\n",
        "        \n",
        "        if len(i.find_all(\"span\")) < 2:\n",
        "            result[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
        "            result['Year'].append(0)\n",
        "\n",
        "        elif len(i.find_all(\"span\")) > 2:\n",
        "            result[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
        "            result['Year'].append(i.find_all(\"span\")[2].text.split()[1])\n",
        "        \n",
        "        else:\n",
        "            result[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
        "            result['Year'].append(i.find_all(\"span\")[1].text.split()[1])\n",
        "    for i in d1_soup.find_all(\"div\", attrs={'class':'snippet'}):\n",
        "        \n",
        "        result[\"Abstract\"].append(i.text)\n",
        "    \n",
        "    \n",
        "print(len(result[\"Title\"]))\n",
        "print(len(result[\"Authors\"]))\n",
        "print(len(result[\"Year\"]))\n",
        "print(len(result[\"Abstract\"]))\n",
        "df = pd.DataFrame(result)\n",
        "print(df.head())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c3deo__qjXZ"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "ClQFGOO8qjXa",
        "outputId": "0a9a0a34-459c-4a35-e705-535780ec6d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    0                   1   \\\n",
              "0    RT @itsdjpriminista: is now playing ‚ô´: #JP - #... 2022-09-26 04:06:36   \n",
              "1    is now playing ‚ô´: #JP - #Covid-19_Modern_Warfa... 2022-09-26 04:06:31   \n",
              "2    RT @hbcu_shitposter: Me in 2040: So there was ... 2022-09-26 04:06:23   \n",
              "3    RT @profesterman: Cases of new COVID-19 varian... 2022-09-26 04:06:20   \n",
              "4    @Jim_Jordan VIDEO: Trump Got Secretly Vaccinat... 2022-09-26 04:05:32   \n",
              "..                                                 ...                 ...   \n",
              "995  Me in 2040: So there was this gorilla that got... 2022-09-25 23:48:40   \n",
              "996  RT @AimHardoi: Most Important information beca... 2022-09-25 23:48:33   \n",
              "997  RT @jamesvgingerich: #WhosNext?  Surely the se... 2022-09-25 23:48:15   \n",
              "998  RT @jsolomonReports: Feds award $1 million to ... 2022-09-25 23:47:56   \n",
              "999  Watching an episode of Law &amp; Order from 20... 2022-09-25 23:47:28   \n",
              "\n",
              "                      2                      3                4   \\\n",
              "0    1574249049934405633             H√©pha√Østos    hephaistos_ai   \n",
              "1    1574249028304478208   Dj Priminista [LIVE]  itsdjpriminista   \n",
              "2    1574248995131629569       Patrick Holderby    QwertyClergy1   \n",
              "3    1574248982242799616            Chris Munro        ChrisClme   \n",
              "4    1574248780647448576              ValeriusX       x_valerius   \n",
              "..                   ...                    ...              ...   \n",
              "995  1574184139737255936  Blessed Shitposter üáªüá¶  hbcu_shitposter   \n",
              "996  1574184109832040448         D' brahmin ¬∞œÄ¬∞      brahmonamah   \n",
              "997  1574184033688457217       Derossi Sieyodji         DerossiS   \n",
              "998  1574183955351339008       Kelly Cunningham        krccanuck   \n",
              "999  1574183838057742337                 Lakeya   MsSpencer_xoxo   \n",
              "\n",
              "                      5                   6                        7   \\\n",
              "0    1151202637582348294               Paris  https://t.co/r220FT6JBq   \n",
              "1     782937333498781696  üá¨üáßüá¨üá≠üáØüá≤üá∫üá∏ #WORLWIDE  https://t.co/3MMALs8ar3   \n",
              "2    1375465216994115586      Tennessee, USA                     None   \n",
              "3              972888836                                         None   \n",
              "4    1564629698528702470              Ulthar                     None   \n",
              "..                   ...                 ...                      ...   \n",
              "995  1489014408248496131     Vienna, Austria                     None   \n",
              "996  1394040438290407425                                         None   \n",
              "997            347318132   Douala, Cameroon   https://t.co/pSiIJVjLMy   \n",
              "998           1055536236                                         None   \n",
              "999            269082707      North Carolina                     None   \n",
              "\n",
              "                                                    8      9     10    11  \\\n",
              "0    H√©pha√Østos has won 5 competitions and is frequ...  False  4607   207   \n",
              "1    Proud Father,VYBZ FAMILY INNA CLASS, DJ https:...  False   126   201   \n",
              "2                     I play Pok√©mon and drink monster  False    12   114   \n",
              "3    Compassion and Respect~ Retweets do not necess...  False   506   711   \n",
              "4    Gandhi ‚Äî ‚ÄúThe greatness of humanity is not in ...  False    12    15   \n",
              "..                                                 ...    ...   ...   ...   \n",
              "995           Deus Vult ‚òß üèõüáªüá¶ ‚öîÔ∏è üõ°also anime ramblings  False   310  1665   \n",
              "996  ‡§ú‡§ü‡§æ‡§ü‡§µ‡•Ä‡§ó‡§≤‡§ú‡•ç‡§ú‡§≤ ‡§™‡•ç‡§∞‡§µ‡§æ‡§π‡§™‡§æ‡§µ‡§ø‡§§‡§∏‡•ç‡§•‡§≤‡•á\\n\\n‡§ó‡§≤‡•á‡§Ω‡§µ‡§≤‡§Æ‡•ç‡§¨‡•ç‡§Ø ‡§≤...  False    53   591   \n",
              "997  Logistics is my philosophy, I respect the cons...  False   241   920   \n",
              "998                                                     False   191    69   \n",
              "999                                                     False   625   741   \n",
              "\n",
              "         12      13  14                  15  \\\n",
              "0    262536  393554  13 2019-07-16 18:51:11   \n",
              "1      2494   43664   1 2016-10-03 13:36:21   \n",
              "2       894     114   0 2021-03-26 15:10:45   \n",
              "3     12632   56539  55 2012-11-26 23:18:30   \n",
              "4       239    1876   0 2022-08-30 15:03:15   \n",
              "..      ...     ...  ..                 ...   \n",
              "995    1732    1034   6 2022-02-02 23:14:42   \n",
              "996     121     779   0 2021-05-16 21:22:15   \n",
              "997    2465    1682   0 2011-08-02 16:22:17   \n",
              "998   50512   96136   3 2013-01-02 16:43:14   \n",
              "999   22924   29672   0 2011-03-20 02:20:33   \n",
              "\n",
              "                                                    16     17     18  \n",
              "0    https://pbs.twimg.com/profile_images/140158061...   True  False  \n",
              "1    https://pbs.twimg.com/profile_images/154269849...   True  False  \n",
              "2    https://pbs.twimg.com/profile_images/143255065...   True  False  \n",
              "3    https://pbs.twimg.com/profile_images/147569205...   True  False  \n",
              "4    https://pbs.twimg.com/profile_images/156469405...   True  False  \n",
              "..                                                 ...    ...    ...  \n",
              "995  https://pbs.twimg.com/profile_images/156949737...   True  False  \n",
              "996  https://pbs.twimg.com/profile_images/140297147...   True  False  \n",
              "997  https://pbs.twimg.com/profile_images/156977865...   True  False  \n",
              "998  https://abs.twimg.com/sticky/default_profile_i...   True   True  \n",
              "999  https://pbs.twimg.com/profile_images/155342342...  False  False  \n",
              "\n",
              "[1000 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff088111-b7af-44fa-9732-8d3e8bd376f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @itsdjpriminista: is now playing ‚ô´: #JP - #...</td>\n",
              "      <td>2022-09-26 04:06:36</td>\n",
              "      <td>1574249049934405633</td>\n",
              "      <td>H√©pha√Østos</td>\n",
              "      <td>hephaistos_ai</td>\n",
              "      <td>1151202637582348294</td>\n",
              "      <td>Paris</td>\n",
              "      <td>https://t.co/r220FT6JBq</td>\n",
              "      <td>H√©pha√Østos has won 5 competitions and is frequ...</td>\n",
              "      <td>False</td>\n",
              "      <td>4607</td>\n",
              "      <td>207</td>\n",
              "      <td>262536</td>\n",
              "      <td>393554</td>\n",
              "      <td>13</td>\n",
              "      <td>2019-07-16 18:51:11</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/140158061...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is now playing ‚ô´: #JP - #Covid-19_Modern_Warfa...</td>\n",
              "      <td>2022-09-26 04:06:31</td>\n",
              "      <td>1574249028304478208</td>\n",
              "      <td>Dj Priminista [LIVE]</td>\n",
              "      <td>itsdjpriminista</td>\n",
              "      <td>782937333498781696</td>\n",
              "      <td>üá¨üáßüá¨üá≠üáØüá≤üá∫üá∏ #WORLWIDE</td>\n",
              "      <td>https://t.co/3MMALs8ar3</td>\n",
              "      <td>Proud Father,VYBZ FAMILY INNA CLASS, DJ https:...</td>\n",
              "      <td>False</td>\n",
              "      <td>126</td>\n",
              "      <td>201</td>\n",
              "      <td>2494</td>\n",
              "      <td>43664</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-10-03 13:36:21</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/154269849...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @hbcu_shitposter: Me in 2040: So there was ...</td>\n",
              "      <td>2022-09-26 04:06:23</td>\n",
              "      <td>1574248995131629569</td>\n",
              "      <td>Patrick Holderby</td>\n",
              "      <td>QwertyClergy1</td>\n",
              "      <td>1375465216994115586</td>\n",
              "      <td>Tennessee, USA</td>\n",
              "      <td>None</td>\n",
              "      <td>I play Pok√©mon and drink monster</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>114</td>\n",
              "      <td>894</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-26 15:10:45</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/143255065...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @profesterman: Cases of new COVID-19 varian...</td>\n",
              "      <td>2022-09-26 04:06:20</td>\n",
              "      <td>1574248982242799616</td>\n",
              "      <td>Chris Munro</td>\n",
              "      <td>ChrisClme</td>\n",
              "      <td>972888836</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>Compassion and Respect~ Retweets do not necess...</td>\n",
              "      <td>False</td>\n",
              "      <td>506</td>\n",
              "      <td>711</td>\n",
              "      <td>12632</td>\n",
              "      <td>56539</td>\n",
              "      <td>55</td>\n",
              "      <td>2012-11-26 23:18:30</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/147569205...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Jim_Jordan VIDEO: Trump Got Secretly Vaccinat...</td>\n",
              "      <td>2022-09-26 04:05:32</td>\n",
              "      <td>1574248780647448576</td>\n",
              "      <td>ValeriusX</td>\n",
              "      <td>x_valerius</td>\n",
              "      <td>1564629698528702470</td>\n",
              "      <td>Ulthar</td>\n",
              "      <td>None</td>\n",
              "      <td>Gandhi ‚Äî ‚ÄúThe greatness of humanity is not in ...</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>239</td>\n",
              "      <td>1876</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-08-30 15:03:15</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/156469405...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Me in 2040: So there was this gorilla that got...</td>\n",
              "      <td>2022-09-25 23:48:40</td>\n",
              "      <td>1574184139737255936</td>\n",
              "      <td>Blessed Shitposter üáªüá¶</td>\n",
              "      <td>hbcu_shitposter</td>\n",
              "      <td>1489014408248496131</td>\n",
              "      <td>Vienna, Austria</td>\n",
              "      <td>None</td>\n",
              "      <td>Deus Vult ‚òß üèõüáªüá¶ ‚öîÔ∏è üõ°also anime ramblings</td>\n",
              "      <td>False</td>\n",
              "      <td>310</td>\n",
              "      <td>1665</td>\n",
              "      <td>1732</td>\n",
              "      <td>1034</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-02-02 23:14:42</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/156949737...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>RT @AimHardoi: Most Important information beca...</td>\n",
              "      <td>2022-09-25 23:48:33</td>\n",
              "      <td>1574184109832040448</td>\n",
              "      <td>D' brahmin ¬∞œÄ¬∞</td>\n",
              "      <td>brahmonamah</td>\n",
              "      <td>1394040438290407425</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>‡§ú‡§ü‡§æ‡§ü‡§µ‡•Ä‡§ó‡§≤‡§ú‡•ç‡§ú‡§≤ ‡§™‡•ç‡§∞‡§µ‡§æ‡§π‡§™‡§æ‡§µ‡§ø‡§§‡§∏‡•ç‡§•‡§≤‡•á\\n\\n‡§ó‡§≤‡•á‡§Ω‡§µ‡§≤‡§Æ‡•ç‡§¨‡•ç‡§Ø ‡§≤...</td>\n",
              "      <td>False</td>\n",
              "      <td>53</td>\n",
              "      <td>591</td>\n",
              "      <td>121</td>\n",
              "      <td>779</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-05-16 21:22:15</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/140297147...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>RT @jamesvgingerich: #WhosNext?  Surely the se...</td>\n",
              "      <td>2022-09-25 23:48:15</td>\n",
              "      <td>1574184033688457217</td>\n",
              "      <td>Derossi Sieyodji</td>\n",
              "      <td>DerossiS</td>\n",
              "      <td>347318132</td>\n",
              "      <td>Douala, Cameroon</td>\n",
              "      <td>https://t.co/pSiIJVjLMy</td>\n",
              "      <td>Logistics is my philosophy, I respect the cons...</td>\n",
              "      <td>False</td>\n",
              "      <td>241</td>\n",
              "      <td>920</td>\n",
              "      <td>2465</td>\n",
              "      <td>1682</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-08-02 16:22:17</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/156977865...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>RT @jsolomonReports: Feds award $1 million to ...</td>\n",
              "      <td>2022-09-25 23:47:56</td>\n",
              "      <td>1574183955351339008</td>\n",
              "      <td>Kelly Cunningham</td>\n",
              "      <td>krccanuck</td>\n",
              "      <td>1055536236</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>191</td>\n",
              "      <td>69</td>\n",
              "      <td>50512</td>\n",
              "      <td>96136</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-01-02 16:43:14</td>\n",
              "      <td>https://abs.twimg.com/sticky/default_profile_i...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Watching an episode of Law &amp;amp; Order from 20...</td>\n",
              "      <td>2022-09-25 23:47:28</td>\n",
              "      <td>1574183838057742337</td>\n",
              "      <td>Lakeya</td>\n",
              "      <td>MsSpencer_xoxo</td>\n",
              "      <td>269082707</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>625</td>\n",
              "      <td>741</td>\n",
              "      <td>22924</td>\n",
              "      <td>29672</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-03-20 02:20:33</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/155342342...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff088111-b7af-44fa-9732-8d3e8bd376f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff088111-b7af-44fa-9732-8d3e8bd376f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff088111-b7af-44fa-9732-8d3e8bd376f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "query = 'Coronavirus'\n",
        "maximumtweets = 1000\n",
        "cons_key = \"2Em7SxlX9jPMfL4x97r3zMO0x\"\n",
        "consr_secret = \"sVbJzekKuiAgq83Y7gCwNVbSowqQokGVzWexKHl2cXIPceWtSd\"\n",
        "token = \"1439767876962029572-uUMt8oWRyzj9ilE5zk4uYbL93sCMPT\"\n",
        "secret_token = \"oydIGymn9bS767FVEMawE9GyGAnMmBJfaY2XXKmHnmliF\"\n",
        "auth = tweepy.OAuthHandler(cons_key, consr_secret)\n",
        "auth.set_access_token(token, secret_token)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "tweet = tweepy.Cursor(api.search,q=query,lang='en').items(maximumtweets)\n",
        "tweet_list = [[twt.text, twt.created_at, twt.id_str, twt.user.name, twt.user.screen_name, twt.user.id_str, twt.user.location, twt.user.url, twt.user.description, twt.user.verified, twt.user.followers_count, twt.user.friends_count, twt.user.favourites_count, twt.user.statuses_count, twt.user.listed_count, twt.user.created_at, twt.user.profile_image_url_https, twt.user.default_profile, twt.user.default_profile_image] for twt in tweet]\n",
        "tweet_df = pd.DataFrame(tweet_list)\n",
        "\n",
        "Tweets = pd.DataFrame()\n",
        "Tweets['User_Name'] = tweet_df[4]\n",
        "Tweets['Posted_Time'] = tweet_df[1]\n",
        "Tweets['Text'] = tweet_df[0]\n",
        "Tweets\n",
        "tweet_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcJNgOMXqjXa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}